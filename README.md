# ğŸ“ˆ QuantCast â€“ Stock Price Forecasting with Hybrid Models (AWS + ML)

## ğŸ“Œ Project Overview
**QuantCast** is an end-to-end pipeline that predicts **next-day returns** and **volatility** for a small watchlist of assets (e.g., AAPL, MSFT, BTC-USD).  
It combines **classical time-series models** (ARIMA/GARCH) with **deep learning (LSTM)** and is designed to be **AWS-native** for scalability.  

The project demonstrates:
- Data ingestion & feature engineering
- Hybrid quant + ML modeling
- Backtesting & performance evaluation
- (Planned) AWS deployment with SageMaker, Lambda, and QuickSight

---

## ğŸ› ï¸ Tech Stack
- **Python** (Pandas, NumPy, Statsmodels, PyTorch, Scikit-learn)
- **yfinance** â€“ historical market data
- **Matplotlib** â€“ local visualizations
- **AWS (Planned)**:
  - S3 (data lake)
  - Lambda + EventBridge (automation)
  - SageMaker (training & deployment)
  - DynamoDB (prediction storage)
  - QuickSight (dashboarding)

---

## ğŸ“‚ Project Structure
QuantCast/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # raw market data from yfinance
â”‚ â””â”€â”€ processed/ # engineered features (Parquet/CSV)
â”‚
â”œâ”€â”€ etl/
â”‚ â”œâ”€â”€ data_collection.py # fetch daily OHLCV data
â”‚ â””â”€â”€ feature_engineering.py# build features (returns, RSI, MA, volatility)
â”‚
â”œâ”€â”€ modeling/
â”‚ â”œâ”€â”€ model_training.py # ARIMA + LSTM training & backtesting
â”‚ â””â”€â”€ deploy_model.py # package/export model artifacts
â”‚
â”œâ”€â”€ serving/
â”‚ â””â”€â”€ batch_infer.py # daily inference (planned for AWS Lambda)
â”‚
â”œâ”€â”€ dashboard/
â”‚ â””â”€â”€ dashboard.py # prototype dashboard (local/Matplotlib â†’ QuickSight later)
â”‚
â”œâ”€â”€ infra/
â”‚ â””â”€â”€ README-aws-setup.md # AWS setup notes (S3, SageMaker, Lambda)
â”‚
â”œâ”€â”€ requirements.txt # dependencies
â””â”€â”€ README.md # this file

---

## âš™ï¸ How It Works
1. **Data Collection**
   - Pulls historical OHLCV data from `yfinance`.
   - Saves files to `data/raw/`.

2. **Feature Engineering**
   - Creates technical indicators:
     - Log returns
     - Rolling mean/volatility
     - RSI
   - Saves to `data/processed/`.

3. **Model Training**
   - Classical: ARIMA for returns, GARCH for volatility.
   - Deep Learning: LSTM on feature windows.
   - Backtests with walk-forward validation.
   - Metrics: MAE, directional accuracy, Sharpe ratio.

4. **Serving (Planned)**
   - Deploys best model to **AWS SageMaker Endpoint**.
   - **Lambda** runs daily to fetch new data and store predictions.

5. **Dashboard (Planned)**
   - Local prototype in Matplotlib.
   - AWS QuickSight for live trader dashboard.

---

## ğŸš€ Getting Started

### 1. Clone Repo
```bash
git clone https://github.com/yourusername/QuantCast.git
cd QuantCast
```
### 2. Install Dependencies
```bash
pip install -r requirements.txt
```
3. Run Data Collection
```bash
python etl/data_collection.py
```
4. Run Feature Engineering
```bash
python etl/feature_engineering.py
```

5. Train Models
```bash
python modeling/model_training.py
```
ğŸ“Š Example Output (local)

Features CSV/Parquet with returns, RSI, moving averages.

Plots:

Predicted vs actual returns.

Directional accuracy (up/down).

Strategy P&L curve.

ğŸ§  Learning Outcomes

Build quant-style ML models for financial time series.

Apply walk-forward backtesting to avoid leakage.

Practice AWS ML pipeline design (S3 â†’ SageMaker â†’ Lambda â†’ QuickSight).

Deploy ML models as daily prediction services.

ğŸ”® Roadmap

 Local data collection & feature engineering

 Baseline ARIMA + LSTM training

 Backtesting & performance evaluation

 AWS S3 integration

 SageMaker training/deployment

 Lambda daily batch predictions

 QuickSight dashboard

ğŸ“œ License

MIT License â€“ feel free to use and adapt.


---

Do you want me to also include a **diagram (ASCII or simple image)** showing the pipeline flow (Data â†’ Features â†’ Models â†’ Predictions â†’ Dashboard) so it looks more â€œexecutive readyâ€ for recruiters?